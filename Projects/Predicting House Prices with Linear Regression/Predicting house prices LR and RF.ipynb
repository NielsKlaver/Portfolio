{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices\n",
    "\n",
    "In this project i will build a pipeline to transform and select features. The goal is to predict a continous variable \"SalePrice\" . Linear models are well suited to tackle this kind of problems. I added a randomforest to compare results.\n",
    "\n",
    "The dataset used in this project is the Ames Houding dataset which can be downloaded [here](https://www.tandfonline.com/doi/abs/10.1080/10691898.2011.11889627). The dataset contains 2390 data points. and a large number of variables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous).\n",
    "\n",
    "This project is based on a project in the dataquest curriculum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2930, 82)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 82 columns):\n",
      "Order              2930 non-null int64\n",
      "PID                2930 non-null int64\n",
      "MS SubClass        2930 non-null int64\n",
      "MS Zoning          2930 non-null object\n",
      "Lot Frontage       2440 non-null float64\n",
      "Lot Area           2930 non-null int64\n",
      "Street             2930 non-null object\n",
      "Alley              198 non-null object\n",
      "Lot Shape          2930 non-null object\n",
      "Land Contour       2930 non-null object\n",
      "Utilities          2930 non-null object\n",
      "Lot Config         2930 non-null object\n",
      "Land Slope         2930 non-null object\n",
      "Neighborhood       2930 non-null object\n",
      "Condition 1        2930 non-null object\n",
      "Condition 2        2930 non-null object\n",
      "Bldg Type          2930 non-null object\n",
      "House Style        2930 non-null object\n",
      "Overall Qual       2930 non-null int64\n",
      "Overall Cond       2930 non-null int64\n",
      "Year Built         2930 non-null int64\n",
      "Year Remod/Add     2930 non-null int64\n",
      "Roof Style         2930 non-null object\n",
      "Roof Matl          2930 non-null object\n",
      "Exterior 1st       2930 non-null object\n",
      "Exterior 2nd       2930 non-null object\n",
      "Mas Vnr Type       2907 non-null object\n",
      "Mas Vnr Area       2907 non-null float64\n",
      "Exter Qual         2930 non-null object\n",
      "Exter Cond         2930 non-null object\n",
      "Foundation         2930 non-null object\n",
      "Bsmt Qual          2850 non-null object\n",
      "Bsmt Cond          2850 non-null object\n",
      "Bsmt Exposure      2847 non-null object\n",
      "BsmtFin Type 1     2850 non-null object\n",
      "BsmtFin SF 1       2929 non-null float64\n",
      "BsmtFin Type 2     2849 non-null object\n",
      "BsmtFin SF 2       2929 non-null float64\n",
      "Bsmt Unf SF        2929 non-null float64\n",
      "Total Bsmt SF      2929 non-null float64\n",
      "Heating            2930 non-null object\n",
      "Heating QC         2930 non-null object\n",
      "Central Air        2930 non-null object\n",
      "Electrical         2929 non-null object\n",
      "1st Flr SF         2930 non-null int64\n",
      "2nd Flr SF         2930 non-null int64\n",
      "Low Qual Fin SF    2930 non-null int64\n",
      "Gr Liv Area        2930 non-null int64\n",
      "Bsmt Full Bath     2928 non-null float64\n",
      "Bsmt Half Bath     2928 non-null float64\n",
      "Full Bath          2930 non-null int64\n",
      "Half Bath          2930 non-null int64\n",
      "Bedroom AbvGr      2930 non-null int64\n",
      "Kitchen AbvGr      2930 non-null int64\n",
      "Kitchen Qual       2930 non-null object\n",
      "TotRms AbvGrd      2930 non-null int64\n",
      "Functional         2930 non-null object\n",
      "Fireplaces         2930 non-null int64\n",
      "Fireplace Qu       1508 non-null object\n",
      "Garage Type        2773 non-null object\n",
      "Garage Yr Blt      2771 non-null float64\n",
      "Garage Finish      2771 non-null object\n",
      "Garage Cars        2929 non-null float64\n",
      "Garage Area        2929 non-null float64\n",
      "Garage Qual        2771 non-null object\n",
      "Garage Cond        2771 non-null object\n",
      "Paved Drive        2930 non-null object\n",
      "Wood Deck SF       2930 non-null int64\n",
      "Open Porch SF      2930 non-null int64\n",
      "Enclosed Porch     2930 non-null int64\n",
      "3Ssn Porch         2930 non-null int64\n",
      "Screen Porch       2930 non-null int64\n",
      "Pool Area          2930 non-null int64\n",
      "Pool QC            13 non-null object\n",
      "Fence              572 non-null object\n",
      "Misc Feature       106 non-null object\n",
      "Misc Val           2930 non-null int64\n",
      "Mo Sold            2930 non-null int64\n",
      "Yr Sold            2930 non-null int64\n",
      "Sale Type          2930 non-null object\n",
      "Sale Condition     2930 non-null object\n",
      "SalePrice          2930 non-null int64\n",
      "dtypes: float64(11), int64(28), object(43)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions which I will update later. Transform, select, train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 57088.0\n"
     ]
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):  \n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    numeric_train = train.select_dtypes(include=[np.number])\n",
    "    numeric_test = test.select_dtypes(include=[np.number])\n",
    "    \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    \n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(train[features], train[\"SalePrice\"])\n",
    "    \n",
    "    predictions = lr.predict(test[features])\n",
    "    \n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "print(\"Baseline RMSE:\" ,round(rmse) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our functions. Run the model for the first time with only the \"Gr Liv Area\" feature I get a baseline RMSE of 57000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values and create new feautures\n",
    "\n",
    "__For now:__\n",
    "* I will drop all columns with missing values > 5 % \n",
    "* On text columns I will drop columns with any missing values\n",
    "* On numerical columns fill with most common value . I create a dictionary with mode per column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_missing = df.isnull().sum()\n",
    "drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "df = df.drop(drop_missing_cols.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "drop_missing_cols_txt = text_mv_counts[text_mv_counts > 0]\n",
    "df = df.drop(drop_missing_cols_txt.index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1       1\n",
       "BsmtFin SF 2       1\n",
       "Bsmt Unf SF        1\n",
       "Total Bsmt SF      1\n",
       "Garage Cars        1\n",
       "Garage Area        1\n",
       "Bsmt Full Bath     2\n",
       "Bsmt Half Bath     2\n",
       "Mas Vnr Area      23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_missing = df.select_dtypes(include=[np.number]).isnull().sum()\n",
    "fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "fixable_numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BsmtFin SF 1': 0.0,\n",
       " 'BsmtFin SF 2': 0.0,\n",
       " 'Bsmt Unf SF': 0.0,\n",
       " 'Total Bsmt SF': 0.0,\n",
       " 'Garage Cars': 2.0,\n",
       " 'Garage Area': 0.0,\n",
       " 'Bsmt Full Bath': 0.0,\n",
       " 'Bsmt Half Bath': 0.0,\n",
       " 'Mas Vnr Area': 0.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "replacement_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(replacement_values_dict)\n",
    "df.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create features based on year sold and and years since remod. Also check if values make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_sold = df['Yr Sold'] - df['Year Built']\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "years_since_remod[years_since_remod < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Years Before Sale'] = years_sold\n",
    "df['Years Since Remod'] = years_since_remod\n",
    "\n",
    "df = df.drop([1702, 2180, 2181], axis=0)\n",
    "df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are not usefull for Machine Learning and columns that leak information about the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"PID\", \"Order\"], axis=1)\n",
    "df = df.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update transform_features function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=[np.number]).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):  \n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    numeric_train = train.select_dtypes(include=[np.number])\n",
    "    numeric_test = test.select_dtypes(include=[np.number])\n",
    "        \n",
    "    features = numeric_train.columns.drop(\"SalePrice\")\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(train[features], train[\"SalePrice\"])\n",
    "    predictions = lr.predict(test[features])\n",
    "    mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New RMSE: 55275.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "print(\"New RMSE:\" ,round(rmse) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature selection\n",
    "\n",
    "First I will select numerical features and check if they are correlated with the sales price.\n",
    "I will set a threshold of absolute correlation of 40% (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>2nd Flr SF</th>\n",
       "      <th>Low Qual Fin SF</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Bsmt Full Bath</th>\n",
       "      <th>Bsmt Half Bath</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>Half Bath</th>\n",
       "      <th>Bedroom AbvGr</th>\n",
       "      <th>Kitchen AbvGr</th>\n",
       "      <th>TotRms AbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Years Before Sale</th>\n",
       "      <th>Years Since Remod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>215000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>105000</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>2010</td>\n",
       "      <td>172000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>244000</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>1629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>189900</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MS SubClass  Lot Area  Overall Qual  Overall Cond  Mas Vnr Area  \\\n",
       "0           20     31770             6             5         112.0   \n",
       "1           20     11622             5             6           0.0   \n",
       "2           20     14267             6             6         108.0   \n",
       "3           20     11160             7             5           0.0   \n",
       "4           60     13830             5             5           0.0   \n",
       "\n",
       "   BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF  1st Flr SF  \\\n",
       "0         639.0           0.0        441.0         1080.0        1656   \n",
       "1         468.0         144.0        270.0          882.0         896   \n",
       "2         923.0           0.0        406.0         1329.0        1329   \n",
       "3        1065.0           0.0       1045.0         2110.0        2110   \n",
       "4         791.0           0.0        137.0          928.0         928   \n",
       "\n",
       "   2nd Flr SF  Low Qual Fin SF  Gr Liv Area  Bsmt Full Bath  Bsmt Half Bath  \\\n",
       "0           0                0         1656             1.0             0.0   \n",
       "1           0                0          896             0.0             0.0   \n",
       "2           0                0         1329             0.0             0.0   \n",
       "3           0                0         2110             1.0             0.0   \n",
       "4         701                0         1629             0.0             0.0   \n",
       "\n",
       "   Full Bath  Half Bath  Bedroom AbvGr  Kitchen AbvGr  TotRms AbvGrd  \\\n",
       "0          1          0              3              1              7   \n",
       "1          1          0              2              1              5   \n",
       "2          1          1              3              1              6   \n",
       "3          2          1              3              1              8   \n",
       "4          2          1              3              1              6   \n",
       "\n",
       "   Fireplaces  Garage Cars  Garage Area  Wood Deck SF  Open Porch SF  \\\n",
       "0           2          2.0        528.0           210             62   \n",
       "1           0          1.0        730.0           140              0   \n",
       "2           0          1.0        312.0           393             36   \n",
       "3           2          2.0        522.0             0              0   \n",
       "4           1          2.0        482.0           212             34   \n",
       "\n",
       "   Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area  Misc Val  Yr Sold  \\\n",
       "0               0           0             0          0         0     2010   \n",
       "1               0           0           120          0         0     2010   \n",
       "2               0           0             0          0     12500     2010   \n",
       "3               0           0             0          0         0     2010   \n",
       "4               0           0             0          0         0     2010   \n",
       "\n",
       "   SalePrice  Years Before Sale  Years Since Remod  \n",
       "0     215000                 50                 50  \n",
       "1     105000                 49                 49  \n",
       "2     172000                 52                 52  \n",
       "3     244000                 42                 42  \n",
       "4     189900                 13                 12  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = transform_df.select_dtypes(include=[np.number])\n",
    "numerical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Overall Qual         0.801206\n",
       "Mas Vnr Area         0.506983\n",
       "BsmtFin SF 1         0.439284\n",
       "Total Bsmt SF        0.644012\n",
       "1st Flr SF           0.635185\n",
       "Gr Liv Area          0.717596\n",
       "Full Bath            0.546118\n",
       "TotRms AbvGrd        0.498574\n",
       "Fireplaces           0.474831\n",
       "Garage Cars          0.648361\n",
       "Garage Area          0.641425\n",
       "SalePrice            1.000000\n",
       "Years Before Sale    0.558979\n",
       "Years Since Remod    0.534985\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs()\n",
    "abs_corr_coeffs[abs_corr_coeffs > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_df = transform_df.drop(abs_corr_coeffs[abs_corr_coeffs < 0.4].index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix categorical columns. Which numerical columns should be converted to category because a ranking does not make sense. Create dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the beginning i dropped several columns. Now i need to check which are in the df and how many unique values they have. If it has 10 or less values --> create dummies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cat_cols = []\n",
    "\n",
    "for col in nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        transform_cat_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Street           2\n",
       "Central Air      2\n",
       "Land Contour     4\n",
       "Lot Config       5\n",
       "Bldg Type        5\n",
       "Roof Style       6\n",
       "Foundation       6\n",
       "Heating          6\n",
       "MS Zoning        7\n",
       "Condition 2      8\n",
       "House Style      8\n",
       "Roof Matl        8\n",
       "Condition 1      9\n",
       "Exterior 1st    16\n",
       "Exterior 2nd    17\n",
       "Neighborhood    28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueness_counts = transform_df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "uniqueness_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > 10].index\n",
    "transform_df = transform_df.drop(drop_nonuniq_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = transform_df.select_dtypes(include=['object'])\n",
    "for col in text_cols:\n",
    "    transform_df[col] = transform_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_df = pd.concat([transform_df,pd.get_dummies(transform_df.select_dtypes(include=['category']))], axis=1).drop(text_cols,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update select features and implement kfold cross validation for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=[np.number]).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    return df\n",
    "\n",
    "def select_features(df, coeff_threshold=0.4, uniq_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=[np.number])\n",
    "    abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    \n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "\n",
    "    uniqueness_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > 10].index\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(text_cols,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    lr = linear_model.LinearRegression()\n",
    "    \n",
    "    if k == 0:\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        return rmse\n",
    "    \n",
    "    if k == 1:\n",
    "        shuffled_df = df.sample(frac=1, )\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions_one = lr.predict(test[features])        \n",
    "        \n",
    "        mse_one = mean_squared_error(test[\"SalePrice\"], predictions_one)\n",
    "        rmse_one = np.sqrt(mse_one)\n",
    "        \n",
    "        lr.fit(test[features], test[\"SalePrice\"])\n",
    "        predictions_two = lr.predict(train[features])        \n",
    "       \n",
    "        mse_two = mean_squared_error(train[\"SalePrice\"], predictions_two)\n",
    "        rmse_two = np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "        print(rmse_one)\n",
    "        print(rmse_two)\n",
    "        return avg_rmse\n",
    "    else:\n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return avg_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE 28796.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df, k=4)\n",
    "\n",
    "print(\"Final RMSE\", round(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    drop_missing_cols = num_missing[(num_missing > len(df)/20)].sort_values()\n",
    "    df = df.drop(drop_missing_cols.index, axis=1)\n",
    "    \n",
    "    text_mv_counts = df.select_dtypes(include=['object']).isnull().sum().sort_values(ascending=False)\n",
    "    drop_missing_cols_2 = text_mv_counts[text_mv_counts > 0]\n",
    "    df = df.drop(drop_missing_cols_2.index, axis=1)\n",
    "    \n",
    "    num_missing = df.select_dtypes(include=[np.number]).isnull().sum()\n",
    "    fixable_numeric_cols = num_missing[(num_missing < len(df)/20) & (num_missing > 0)].sort_values()\n",
    "    replacement_values_dict = df[fixable_numeric_cols.index].mode().to_dict(orient='records')[0]\n",
    "    df = df.fillna(replacement_values_dict)\n",
    "    \n",
    "    years_sold = df['Yr Sold'] - df['Year Built']\n",
    "    years_since_remod = df['Yr Sold'] - df['Year Remod/Add']\n",
    "    df['Years Before Sale'] = years_sold\n",
    "    df['Years Since Remod'] = years_since_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "    df = df.drop([\"PID\", \"Order\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    return df\n",
    "\n",
    "def select_features(df, coeff_threshold=0.4, uniq_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=[np.number])\n",
    "    abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    \n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "\n",
    "    uniqueness_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > 10].index\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(text_cols,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    lr = linear_model.LinearRegression()\n",
    "    forest = RandomForestRegressor(n_estimators = 100, random_state = 0) \n",
    "    models = [lr,forest]\n",
    "    for model in models:\n",
    "        if k == 0:\n",
    "            train = df[:1460]\n",
    "            test = df[1460:]\n",
    "\n",
    "            model.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = model.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            return rmse\n",
    "\n",
    "        if k == 1:\n",
    "            shuffled_df = df.sample(frac=1, )\n",
    "            train = df[:1460]\n",
    "            test = df[1460:]\n",
    "\n",
    "            model.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions_one = model.predict(test[features])        \n",
    "\n",
    "            mse_one = mean_squared_error(test[\"SalePrice\"], predictions_one)\n",
    "            rmse_one = np.sqrt(mse_one)\n",
    "\n",
    "            model.fit(test[features], test[\"SalePrice\"])\n",
    "            predictions_two = model.predict(train[features])        \n",
    "\n",
    "            mse_two = mean_squared_error(train[\"SalePrice\"], predictions_two)\n",
    "            rmse_two = np.sqrt(mse_two)\n",
    "\n",
    "            avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "            print(rmse_one)\n",
    "            print(rmse_two)\n",
    "            return avg_rmse\n",
    "        else:\n",
    "            start = time.time()\n",
    "            kf = KFold(n_splits=k, shuffle=True)\n",
    "            rmse_values = []\n",
    "            for train_index, test_index, in kf.split(df):\n",
    "                train = df.iloc[train_index]\n",
    "                test = df.iloc[test_index]\n",
    "                model.fit(train[features], train[\"SalePrice\"])\n",
    "                predictions = model.predict(test[features])\n",
    "                mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "                rmse = np.sqrt(mse)\n",
    "                rmse_values.append(rmse)\n",
    "            avg_rmse = np.mean(rmse_values)\n",
    "            training_time = time.time() - start\n",
    "            print(model, \"RMSE:\", avg_rmse, 'Training time:', training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) RMSE: 28627.323360628223 Training time: 0.2603030204772949\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
      "                      warm_start=False) RMSE: 25809.196615963738 Training time: 34.706329584121704\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transform_df = transform_features(df)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the simple LinearRegression to the RandomForrest the big advantage of the linear model is it\\`s speed. Training is > 100 times faster. With some more feature engineering I should be able to reduce the 10 % gap in RMSE."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
